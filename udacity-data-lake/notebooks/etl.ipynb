{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['aws']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['aws']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_path = \"output/data-lake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_path = os.path.join(input_path, \"song_data/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('json').load(song_path)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|         artist_id|                name|            location|latitude|longitude|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|AR9AWNF1187B9AB0B4|Kenny G featuring...|Seattle, Washingt...|    null|     null|\n",
      "|AR0IAWL1187B9A96D0|        Danilo Perez|              Panama|  8.4177|-80.11278|\n",
      "|AR0RCMP1187FB3F427|    Billie Jo Spears|        Beaumont, TX|30.08615|-94.10158|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_table = df.select(\\\n",
    "                      'artist_id', \\\n",
    "                      col('artist_name').alias('name'), \\\n",
    "                      col('artist_location').alias('location'), \\\n",
    "                      col('artist_latitude').alias('latitude'), \\\n",
    "                      col('artist_longitude').alias('longitude')).dropDuplicates(subset=['artist_id'])\n",
    "artists_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------------------+----+---------+\n",
      "|           song_id|              title|         artist_id|year| duration|\n",
      "+------------------+-------------------+------------------+----+---------+\n",
      "|SOGOSOV12AF72A285E|  ¿Dónde va Chichi?|ARGUVEV1187B98BA17|1997|313.12934|\n",
      "|SOMZWCG12A8C13C480|   I Didn't Mean To|ARD7TVE1187B99BFB1|   0|218.93179|\n",
      "|SOUPIRU12A6D4FA1E1|Der Kleine Dompfaff|ARJIE2Y1187B994AB7|   0|152.92036|\n",
      "+------------------+-------------------+------------------+----+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_table = df.select('song_id', 'title', 'artist_id', 'year', 'duration').dropDuplicates(subset=['song_id'])\n",
    "songs_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "table_path = os.path.join(output_path, \"songs\")\n",
    "songs_table.write.mode('overwrite').partitionBy(\"year\", \"artist_id\").parquet(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "table_path = os.path.join(output_path, \"artists\")\n",
    "artists_table.write.mode('overwrite').parquet(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_path = os.path.join(input_path, \"events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('json').load(log_path)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.filter(df.page == 'NextSong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table = df.select(\\\n",
    "                                 col('userId').alias('user_id'), \\\n",
    "                                 col('firstName').alias('first_name'), \\\n",
    "                                 col('lastName').alias('last_name'), 'gender', 'level').dropDuplicates(subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "table_path = os.path.join(output_path, \"users\")\n",
    "users_table.write.mode('overwrite').parquet(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "get_timestamp = udf(lambda ts: datetime.fromtimestamp(float(ts)/1000.0), TimestampType())\n",
    "df = df.withColumn('timestamp', get_timestamp('ts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime\n",
    "\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "get_datestamp = udf(lambda ts: datetime.fromtimestamp(float(ts)/1000.0), DateType())\n",
    "df = df.withColumn(\"datetime\", get_datestamp('ts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, hour, dayofweek, dayofyear, weekofyear\n",
    "\n",
    "time_table = df.select(\\\n",
    "                        col('ts').alias('start_time'), 'timestamp', 'datetime',\n",
    "                        hour('timestamp').alias('hour'),\\\n",
    "                        dayofyear('timestamp').alias('day'),\\\n",
    "                       weekofyear('timestamp').alias('week'),\\\n",
    "                       month('timestamp').alias('month'),\\\n",
    "                       year('timestamp').alias('year'),\\\n",
    "                       dayofweek('timestamp').alias('weekday')).dropDuplicates(subset=['start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "table_path = os.path.join(output_path, \"time\")\n",
    "time_table.write.mode('overwrite').partitionBy(\"year\", \"month\").parquet(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+---------+----+------------------+\n",
      "|           song_id|               title| duration|year|         artist_id|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|SOAOIBZ12AB01815BE|I Hold Your Hand ...| 43.36281|2000|ARPBNLO1187FB3D52F|\n",
      "|SONYPOM12A8C13B2D7|I Think My Wife I...|186.48771|2005|ARDNS031187B9924F0|\n",
      "|SODREIN12A58A7F2E5|A Whiter Shade Of...|326.00771|   0|ARLTWXK1187FB5A3F8|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_path = os.path.join(output_path, \"songs\")\n",
    "songs_table = spark.read.parquet(table_path)\n",
    "songs_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|songplay_id|   start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|year|month|\n",
      "+-----------+-------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|          0|1542837407796|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "|          1|1542171963796|     10| free|SOGDBUF12A8C140FAA|AR558FS1187FB45658|       484|Washington-Arling...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|          2|1542618860796|     24| paid|SOGDBUF12A8C140FAA|AR558FS1187FB45658|       672|Lake Havasu City-...|\"Mozilla/5.0 (Win...|2018|   11|\n",
      "+-----------+-------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "songplays_table = df.join(songs_table,  df.song == songs_table.title)\\\n",
    "                    .withColumn('songplay_id', monotonically_increasing_id())\\\n",
    "                    .withColumn('year', year('timestamp')) \\\n",
    "                    .withColumn('month', month('timestamp')) \\\n",
    "                    .select(\\\n",
    "                         'songplay_id',\n",
    "                         col('ts').alias('start_time'),\n",
    "                        col('userId').alias('user_id'),\n",
    "                        'level',\n",
    "                        'song_id',\n",
    "                        'artist_id',\n",
    "                        col('sessionId').alias('session_id'),\n",
    "                        'location',\n",
    "                        col('userAgent').alias('user_agent'),\n",
    "                        'year',\n",
    "                        'month')\n",
    "songplays_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "table_path = os.path.join(output_path, \"songplays\")\n",
    "songplays_table.write.mode('overwrite').partitionBy(\"year\", \"month\").parquet(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
