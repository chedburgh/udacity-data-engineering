{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Engineering Capstone Project\n",
    "\n",
    "### Project Summary\n",
    "The project explores US immigration data alongside US city demographics and world temperature data. The data is explored, then aggregated to build an ETL pipeline inside the notebook. The notebook format was chosen to allow intituative investigation of the data, while still building up the ETL model.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, date_add, col\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "This project will use data from multiple sources and create both fact and dimension tables to allow the user to query for links between destination of travel and the temperature of the travel destination. For example we can query the numbers arriving in a city and its temperature on different months, the length of the stay and the reason.\n",
    "\n",
    "### Describe and Gather Data \n",
    "The following datasets are used in the project:\n",
    "\n",
    "- I94 Immigration Data: This data comes from the US National Tourism and Trade Office and includes the contents of the i94 form on entry to the united states. A data dictionary is included in the workspace. It is provided in SAS7BDAT format which is a binary database storage format.\n",
    "- World Temperature Data: This dataset comes from Kaggle and includes the temperatures of various cities in the world fomr 1743 to 2013. The dataset can be found [here](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "\n",
    "Now lets take a look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Sample Immigration Data\n",
    "\n",
    "The immigration dataset is large, containing around 3 million rows. A sample file can be used to perform an initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration_sample = pd.read_csv('immigration_data_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lets take a look at the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port',\n",
       "       'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa',\n",
       "       'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd',\n",
       "       'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum',\n",
       "       'airline', 'admnum', 'fltno', 'visatype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The columes are defined in the data dictionary included with the workspace (I94_SAS_Labels_Description.SAS). A sample of these are:\n",
    "\n",
    "- i94yr: 4 digit year\n",
    "- i94mon: Numeric month\n",
    "- i94cit: 3 digit code of origin city\n",
    "- i94port: 3 character code of destination USA city\n",
    "- arrdate: Arrival date in the USA\n",
    "- i94mode: 1 digit travel code\n",
    "- depdate: Departure date from the USA\n",
    "- i94visa: Reason for immigration\n",
    "\n",
    "Let's increase the number of columns that can be displayed at once to have a better look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0  20160407      NaN   NaN   \n",
       "3      1.0      CA  20581.0    25.0      2.0    1.0  20160428      DOH   NaN   \n",
       "4      3.0      NY  20553.0    19.0      2.0    1.0  20160406      NaN   NaN   \n",
       "\n",
       "  entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       G       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       G       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "2       G       O      NaN       M   1940.0  07052016      M     NaN      LH   \n",
       "3       G       O      NaN       M   1991.0  10272016      M     NaN      QR   \n",
       "4       Z       K      NaN       M   1997.0  07042016      F     NaN     NaN   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  \n",
       "4  4.232257e+10   LAND       WT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "df_immigration_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data\n",
    "Tourism often displays a strong connection to climate data, so this world temperature data will help explore that. Lets load the data and take a look at its shape and row count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599212, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature = pd.read_csv(fname)\n",
    "df_temperature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration Data Frame\n",
    "We are going to load a full month os immigration data to work with. We also setup a spark session at this point, and will use this in the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.10\")\\\n",
    "    .enableHiveSupport().getOrCreate()\n",
    "\n",
    "def sas_file_to_spark_df(file):\n",
    "    return spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "\n",
    "df_immigration = sas_file_to_spark_df('/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Lets check the data looks like the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Valid Ports\n",
    "Create a dictionary of valid ports from the data dictionary as an additional data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "### i94_port_lines are 303 - 962\n",
    "\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "with open('I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    lines = f.readlines()   \n",
    "\n",
    "exp = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "valid_ports = {}\n",
    "for line in lines[302:961]:\n",
    "    match = exp.search(line)\n",
    "    valid_ports[match.group(1)]=[match.group(2)]\n",
    "\n",
    "#pprint(valid_ports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and Assess the Data\n",
    "### Explore and Clean Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc. During the process we will build up some of the functions we will use in the ETL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration Data\n",
    "For the immigration data, we want to remove all rows where the destination city code i94port is not a valid value. We can find invalid codes in the data dictionary (I94_SAS_Labels_Description.SAS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cicid',\n",
       " 'i94yr',\n",
       " 'i94mon',\n",
       " 'i94cit',\n",
       " 'i94res',\n",
       " 'i94port',\n",
       " 'arrdate',\n",
       " 'i94mode',\n",
       " 'i94addr',\n",
       " 'depdate',\n",
       " 'i94bir',\n",
       " 'i94visa',\n",
       " 'count',\n",
       " 'dtadfile',\n",
       " 'visapost',\n",
       " 'occup',\n",
       " 'entdepa',\n",
       " 'entdepd',\n",
       " 'entdepu',\n",
       " 'matflag',\n",
       " 'biryear',\n",
       " 'dtaddto',\n",
       " 'gender',\n",
       " 'insnum',\n",
       " 'airline',\n",
       " 'admnum',\n",
       " 'fltno',\n",
       " 'visatype']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There is a lot of data here. For the purpose of our pipeline, and since we are interested in looking at correlations between destination and temperature only, we keep the following columns: i94yr, i94mon, i94cit, i94port, i94mode, i94bir, arrdate, depdate and i94visa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_immigration_data(immigration_data):\n",
    "    \n",
    "    # read immigration data into Spark\n",
    "    df_immigration = sas_file_to_spark_df(immigration_data)\n",
    "\n",
    "    # filter out entries where i94port is invalid\n",
    "    df_immigration = df_immigration.filter(df_immigration.i94port.isin(list(valid_ports.keys())))\n",
    "\n",
    "    # filter out the columns we want to keep\n",
    "    columns_to_keep = {'i94yr', 'i94mon', 'i94cit', 'i94port', 'i94mode', 'i94bir', 'arrdate', 'depdate', 'i94visa'}\n",
    "    df_immigration = df_immigration.filter(df_immigration.i94port.isin(list(valid_ports.keys())))\n",
    "    df_immigration = df_immigration.select([c for c in df_immigration.columns if c in columns_to_keep])\n",
    "    \n",
    "    # return the dataframe\n",
    "    return df_immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+-------+-------+-------+-------+------+-------+\n",
      "| i94yr|i94mon|i94cit|i94port|arrdate|i94mode|depdate|i94bir|i94visa|\n",
      "+------+------+------+-------+-------+-------+-------+------+-------+\n",
      "|2016.0|   4.0| 692.0|    XXX|20573.0|   null|   null|  37.0|    2.0|\n",
      "|2016.0|   4.0| 254.0|    ATL|20551.0|    1.0|   null|  25.0|    3.0|\n",
      "|2016.0|   4.0| 101.0|    WAS|20545.0|    1.0|20691.0|  55.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|20567.0|  28.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|20567.0|   4.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|20555.0|  57.0|    1.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|20558.0|  63.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|20558.0|  57.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|20553.0|  46.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|20562.0|  48.0|    1.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|20671.0|  52.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    TOR|20545.0|    1.0|20554.0|  33.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    BOS|20545.0|    1.0|20549.0|  58.0|    1.0|\n",
      "|2016.0|   4.0| 101.0|    ATL|20545.0|    1.0|20549.0|  56.0|    1.0|\n",
      "|2016.0|   4.0| 101.0|    ATL|20545.0|    1.0|20561.0|  62.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    ATL|20545.0|    1.0|20578.0|  49.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    ATL|20545.0|    1.0|20611.0|  43.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    HOU|20545.0|    1.0|20554.0|  53.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|   null|  48.0|    2.0|\n",
      "|2016.0|   4.0| 101.0|    NYC|20545.0|    1.0|   null|  74.0|    2.0|\n",
      "+------+------+------+-------+-------+-------+-------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "immigration_test_file = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df_immigration_test = clean_immigration_data(immigration_test_file)\n",
    "df_immigration_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data\n",
    "\n",
    "Lets look at the temperature data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.651\n",
      "-42.704\n"
     ]
    }
   ],
   "source": [
    "unique_temps = df_temperature.AverageTemperature.unique()\n",
    "print(max(unique_temps))\n",
    "print(min(unique_temps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Average temperature values look ok. We will clean as follows:\n",
    "\n",
    "- We want to drop all entries where AverageTemperature is NaN.\n",
    "- We will drop all entries with duplicate locations\n",
    "- Add the i94port of the location in each entry so it can be joined in the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def csv_file_to_spark_df(file):\n",
    "    return spark.read.format('csv').option('header', 'true').load(file)\n",
    "\n",
    "# define a quick function to convert the city to port value\n",
    "@udf()\n",
    "def convert_city_to_port(city):\n",
    "    for key in valid_ports:\n",
    "        if city.lower() in valid_ports[key][0].lower():\n",
    "            return key\n",
    "\n",
    "def clean_temperature_data(temperature_data_file):\n",
    "    df_temperature = csv_file_to_spark_df(temperature_data_file)\n",
    "    \n",
    "    # remove NaN entries\n",
    "    df_temperature = df_temperature.filter(df_temperature.AverageTemperature != 'NaN')\n",
    "    \n",
    "    # drop duplicates\n",
    "    df_temperature = df_temperature.dropDuplicates(['City', 'Country'])\n",
    "    \n",
    "    # add port code\n",
    "    df_temperature = df_temperature.withColumn('i94port', convert_city_to_port(df_temperature.City))\n",
    "    \n",
    "    # return a data frame that filters any null port codes\n",
    "    return df_temperature.filter(df_temperature.i94port != 'null')\n",
    "\n",
    "df_temperature = clean_temperature_data('../../data2/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-----------------------------+---------+--------------------+--------+---------+-------+\n",
      "|        dt| AverageTemperature|AverageTemperatureUncertainty|     City|             Country|Latitude|Longitude|i94port|\n",
      "+----------+-------------------+-----------------------------+---------+--------------------+--------+---------+-------+\n",
      "|1856-01-01|             26.901|                        1.359|      Ife|             Nigeria|   7.23N|    4.05E|    888|\n",
      "|1852-07-01|             15.488|                        1.395|    Perth|           Australia|  31.35S|  114.97E|    PER|\n",
      "|1828-01-01|             -1.977|                        2.551|  Seattle|       United States|  47.42N|  121.97W|    SEA|\n",
      "|1743-11-01|              2.767|                        1.905| Hamilton|              Canada|  42.59N|   80.73W|    HAM|\n",
      "|1849-01-01|  7.399999999999999|                        2.699|  Ontario|       United States|  34.56N|  116.76W|    ONT|\n",
      "|1821-11-01|              2.322|                        2.375|  Spokane|       United States|  47.42N|  117.24W|    SPO|\n",
      "|1843-01-01| 18.874000000000002|                        2.017|Abu Dhabi|United Arab Emirates|  24.92N|   54.98E|    MAA|\n",
      "|1824-01-01|             25.229|                        1.094|    Anaco|           Venezuela|   8.84N|   64.05W|    ANA|\n",
      "|1855-05-01|              9.904|           1.4369999999999998|      Ica|                Peru|  13.66S|   75.14W|    CHI|\n",
      "|1835-01-01|              9.833|                        2.182|  Nogales|       United States|  31.35N|  111.20W|    NOG|\n",
      "|1743-11-01|  8.129999999999999|                        2.245|  Atlanta|       United States|  34.56N|   83.68W|    ATL|\n",
      "|1796-01-01|             15.552|                        2.305|      Mau|               India|  26.52N|   84.18E|    OGG|\n",
      "|1743-11-01|              3.264|                        1.665|   Newark|       United States|  40.99N|   74.56W|    NEW|\n",
      "|1857-01-01| 18.581000000000003|           1.8119999999999998|  Springs|        South Africa|  26.52S|   28.66E|    PSP|\n",
      "|1856-01-01| 26.055999999999997|           1.3769999999999998|      Ise|             Nigeria|   7.23N|    5.68E|    BOI|\n",
      "|1743-11-01|             18.722|                        2.302|  Orlando|       United States|  28.13N|   80.91W|    ORL|\n",
      "|1823-01-01|             11.602|           2.8160000000000003|   Laredo|       United States|  28.13N|   99.09W|    LCB|\n",
      "|1841-01-01| 13.107999999999999|                        2.519|     Tali|              Taiwan|  24.92N|  120.59E|    MET|\n",
      "|1828-01-01|-2.7630000000000003|                        2.617| Victoria|              Canada|  49.03N|  122.45W|    VIC|\n",
      "|1743-11-01| 1.1880000000000002|                        1.531|   Boston|       United States|  42.59N|   72.00W|    BOS|\n",
      "+----------+-------------------+-----------------------------+---------+--------------------+--------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temperature.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "The model is quite simple, being made up of two staging tables and a final table. Using the staging tables gives us a chance to clean and manipulate the data before it is joined into the final table. The final table will be used to run queries against and provide details on each immigration event. For example, we can run simple queries against this table about the numbers of visitors to each city in a given month and both the temperature and reason for for the visit.\n",
    "\n",
    "These are detailed as follows:\n",
    "\n",
    "Staging table staging_demographics holds the cleaned data from the immigration dataset. Each row represents an act of immigration into the US. It will contain the following columns from the immigration data:\n",
    "\n",
    "- I94Year: Year as a 4 digit number\n",
    "- I94Month: Month as a numeric\n",
    "- I94City: 3 digit code of origin city\n",
    "- I94Port: 3 character code of destination city\n",
    "- I94Mode: 1 digit travel code\n",
    "- I94Birthday: Age of Respondent in Years\n",
    "- ArrDate: Arrival date\n",
    "- DepDate: Departure date\n",
    "- I94Visa: Reason for immigration (Business/Pleasure/Student)\n",
    "\n",
    "The second staging table, staging_temperate, will contain the cleaned city temperature data from the temperature dataset. Each row represents a temperature measurement. It will contain:\n",
    "\n",
    "- I94Port: Code of destination city (pulled from immigration data during cleanup step)\n",
    "- AverageTemperature: Average temperature\n",
    "- City: City name\n",
    "- Country: Country name\n",
    "- Latitude: Latitude\n",
    "- Longitude: Longitude\n",
    "\n",
    "The final table, final_immigration, its made from joining the two staging tables:\n",
    "\n",
    "- Year: Year as a 4 digit number\n",
    "- Month: Month as a numeric\n",
    "- City: 3 digit code of origin city\n",
    "- Destination: 3 character code of destination city\n",
    "- Mode: 1 digit travel code\n",
    "- Birthday: Age of Respondent in Years\n",
    "- ArrDate: Arrival date\n",
    "- DepDate: Departure date\n",
    "- Visa: Reason for immigration (Business/Pleasure/Student)\n",
    "- AverageTemperature: Average temperature of destination city\n",
    "\n",
    "The fact table will be saved to parque files by city.\n",
    "\n",
    "Note how we have trimmed down the datasets to represent just the data we re interested in, that of immigration into the US and city temperature. \n",
    "\n",
    "#### 3.2 Mapping Out Data Pipeline\n",
    "The pipeline can be sumerised as follows:\n",
    "\n",
    "- Clean immigration data using the clean_immigration_data() function developed in step 2. This will result in a spark data frame covering 1 month for each file passed.\n",
    "- Clean temperature data using the clean_temperature_data() funcion developed in step 2. This will result in a spark data frame of temperature data.\n",
    "- Create staging table staging_demographics by selecting columns from cleaned immigration data and write to parquet file partitioned by field I94Port.\n",
    "- Create staging table staging_temperature by selecting columns from cleaned temperature data and write to parquet file partitioned by field I94Port.\n",
    "- Create immigration_events table by joining immigration and temperature staging tables on I94Port. Write to parquet file partitioned by I94Port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model.\n",
    "\n",
    "##### staging_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#immigration_data = '/data/18-83510-I94-Data-2016/*.sas7bdat'\n",
    "immigration_data = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "\n",
    "# load and clean the immigration data\n",
    "staging_demographics = clean_immigration_data(immigration_data)\n",
    "\n",
    "# tidy up the column names inline with the conceptual data model\n",
    "staging_demographics = staging_demographics.withColumnRenamed('i94yr', 'I94Year')\\\n",
    "                                           .withColumnRenamed('i94mon', 'I94Month')\\\n",
    "                                           .withColumnRenamed('i94cit', 'I94City')\\\n",
    "                                           .withColumnRenamed('i94port', 'I94Port')\\\n",
    "                                           .withColumnRenamed('i94mode', 'I94Mode')\\\n",
    "                                           .withColumnRenamed('i94bir', 'I94Birthday')\\\n",
    "                                           .withColumnRenamed('arrdate', 'ArrDate')\\\n",
    "                                           .withColumnRenamed('depdate', 'DepDate')\\\n",
    "                                           .withColumnRenamed('i94visa', 'I94Visa')\n",
    "\n",
    "# now write immigration staging table to parquet files. We partition by I94Port\n",
    "staging_demographics.write.mode('append').partitionBy('I94Port').parquet('/results/staging_demographics.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I94Year',\n",
       " 'I94Month',\n",
       " 'I94City',\n",
       " 'I94Port',\n",
       " 'ArrDate',\n",
       " 'I94Mode',\n",
       " 'DepDate',\n",
       " 'I94Birthday',\n",
       " 'I94Visa']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_demographics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+-------+-------+-------+-------+-----------+-------+\n",
      "|I94Year|I94Month|I94City|I94Port|ArrDate|I94Mode|DepDate|I94Birthday|I94Visa|\n",
      "+-------+--------+-------+-------+-------+-------+-------+-----------+-------+\n",
      "| 2016.0|     4.0|  692.0|    XXX|20573.0|   null|   null|       37.0|    2.0|\n",
      "| 2016.0|     4.0|  254.0|    ATL|20551.0|    1.0|   null|       25.0|    3.0|\n",
      "| 2016.0|     4.0|  101.0|    WAS|20545.0|    1.0|20691.0|       55.0|    2.0|\n",
      "+-------+--------+-------+-------+-------+-------+-------+-----------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staging_demographics.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### staging_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load and clean the temperature data\n",
    "staging_temperature = clean_temperature_data('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "\n",
    "# select the data and rename columns inline with the conceptual data model \n",
    "staging_temperature = staging_temperature.withColumnRenamed('i94port', 'I94Port')\\\n",
    "    .select(['AverageTemperature', 'City', 'Country', 'Latitude', 'Longitude', 'I94Port'])\n",
    "\n",
    "# now write temperature dimension table to parquet files partitioned by I94Port\n",
    "staging_temperature.write.mode('append').partitionBy('I94Port').parquet('/results/staging_temperature.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AverageTemperature', 'City', 'Country', 'Latitude', 'Longitude', 'I94Port']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_temperature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+-------------+--------+---------+-------+\n",
      "|AverageTemperature|   City|      Country|Latitude|Longitude|I94Port|\n",
      "+------------------+-------+-------------+--------+---------+-------+\n",
      "|            26.901|    Ife|      Nigeria|   7.23N|    4.05E|    888|\n",
      "|            15.488|  Perth|    Australia|  31.35S|  114.97E|    PER|\n",
      "|            -1.977|Seattle|United States|  47.42N|  121.97W|    SEA|\n",
      "+------------------+-------+-------------+--------+---------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staging_temperature.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### immigration_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the fact table by joining the immigration and temperature staging tables\n",
    "immigration_events = staging_demographics.join(staging_temperature,  'I94Port')\\\n",
    "                    .select(\\\n",
    "                        col('I94Year').alias('Year'),\n",
    "                        col('I94Month').alias('Month'),\n",
    "                        col('I94City').alias('City'),\n",
    "                        col('I94Port').alias('Port'),\n",
    "                        col('I94Mode').alias('Mode'),\n",
    "                        col('I94Birthday').alias('Birthday'),\n",
    "                        'ArrDate',\n",
    "                        'DepDate',\n",
    "                        'AverageTemperature')\n",
    "\n",
    "# Write fact table to parquet files partitioned by Port\n",
    "immigration_events.write.mode('append').partitionBy('Port').parquet('/results/immigration_events.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year',\n",
       " 'Month',\n",
       " 'City',\n",
       " 'Port',\n",
       " 'Mode',\n",
       " 'Birthday',\n",
       " 'ArrDate',\n",
       " 'DepDate',\n",
       " 'AverageTemperature']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_events.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+----+----+--------+-------+-------+------------------+\n",
      "|  Year|Month| City|Port|Mode|Birthday|ArrDate|DepDate|AverageTemperature|\n",
      "+------+-----+-----+----+----+--------+-------+-------+------------------+\n",
      "|2016.0|  4.0|111.0| SNA| 1.0|    30.0|20545.0|20547.0| 7.168999999999999|\n",
      "|2016.0|  4.0|114.0| SNA| 1.0|    37.0|20545.0|20562.0| 7.168999999999999|\n",
      "|2016.0|  4.0|117.0| SNA| 1.0|    51.0|20545.0|20559.0| 7.168999999999999|\n",
      "+------+-----+-----+----+----+--------+-------+-------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_events.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Check the size of the tables, and ensure they joined correctly.\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# simple check on the size of the table\n",
    "def check_table_not_empty(table):\n",
    "    return len(table.head(1)) > 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_table_not_empty(staging_demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_table_not_empty(staging_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_table_not_empty(immigration_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "##### dim_demographics\n",
    "\n",
    "- I94Year: Year as a 4 digit number\n",
    "- I94Month: Month as a numeric\n",
    "- I94City: 3 digit code of origin city\n",
    "- I94Port: 3 character code of destination city\n",
    "- I94Mode: 1 digit travel code\n",
    "- I94Birthday: Age of Respondent in Years\n",
    "- ArrDate: Arrival date\n",
    "- DepDate: Departure date\n",
    "- I94Visa: Reason for immigration (Business/Pleasure/Student)\n",
    "\n",
    "##### dim_temperate\n",
    "\n",
    "- I94Port: Code of destination city (pulled from immigration data during cleanup step)\n",
    "- AverageTemperature: Average temperature\n",
    "- City: City name\n",
    "- Country: Country name\n",
    "- Latitude: Latitude\n",
    "- Longitude: Longitude\n",
    "\n",
    "##### fact_immigration\n",
    "\n",
    "- Year: Year as a 4 digit number\n",
    "- Month: Month as a numeric\n",
    "- City: 3 digit code of origin city\n",
    "- Destination: 3 character code of destination city\n",
    "- Mode: 1 digit travel code\n",
    "- Birthday: Age of Respondent in Years\n",
    "- ArrDate: Arrival date\n",
    "- DepDate: Departure date\n",
    "- Visa: Reason for immigration (Business/Pleasure/Student)\n",
    "- AverageTemperature: Average temperature of destination city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "To explore the datasets it is simpler via the rich API that Pandas provide. So this was chosen as the initial tool along with the sample data.\n",
    "\n",
    "For the production side of things (building the data pipeline), Spark was chosen since it can handle large amounts of data simply by scaling up the hardware.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "\n",
    "The immigration dataset is provided monthly, so a monthy run would be appropriate.\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " \n",
    " Increase the size of the spark cluster (and so workers) running the batch job. The spark cluster is only required monthly, so workers could be provisioned as required with autoscaling.\n",
    " \n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " \n",
    " Move the ETL into an Airflow pipeline with an SLA for 7am.\n",
    " \n",
    " * The database needed to be accessed by 100+ people.\n",
    " \n",
    " In this scenario, we could publish the parquet files with read only access to HDFS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
